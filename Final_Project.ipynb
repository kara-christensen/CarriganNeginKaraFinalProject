{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i2dsN0NdysAB"
   },
   "outputs": [],
   "source": [
    "# Import the libraries we'll use below.\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style=\"darkgrid\")  # default style\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.get_logger().setLevel('INFO')\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-macosx_10_16_x86_64.whl (54.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 54.7 MB 46.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0; python_version >= \"3.7\" in /Users/karachristensen/opt/anaconda3/lib/python3.8/site-packages (from opencv-python) (1.23.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.1.78\n"
     ]
    }
   ],
   "source": [
    "## Might need to install SMOTE. After install, I needed to close anaconda/jupyter notebook and reopen it for it to\n",
    "## work :) - Kara\n",
    "##Also import opencv-python for image augmentation- Negin\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "n-wvLSpkzGY5"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('KidneyImages/kidneyData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "ydav9VmY0JNs",
    "outputId": "5083a436-fa8f-48ac-eb07-6e0afd72c5cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_id</th>\n",
       "      <th>path</th>\n",
       "      <th>diag</th>\n",
       "      <th>target</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Tumor- (1044)</td>\n",
       "      <td>/content/data/CT KIDNEY DATASET Normal, CYST, ...</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>3</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tumor- (83)</td>\n",
       "      <td>/content/data/CT KIDNEY DATASET Normal, CYST, ...</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>3</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tumor- (580)</td>\n",
       "      <td>/content/data/CT KIDNEY DATASET Normal, CYST, ...</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>3</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tumor- (1701)</td>\n",
       "      <td>/content/data/CT KIDNEY DATASET Normal, CYST, ...</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>3</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tumor- (1220)</td>\n",
       "      <td>/content/data/CT KIDNEY DATASET Normal, CYST, ...</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>3</td>\n",
       "      <td>Tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12441</th>\n",
       "      <td>12441</td>\n",
       "      <td>Cyst- (2522)</td>\n",
       "      <td>/content/data/CT KIDNEY DATASET Normal, CYST, ...</td>\n",
       "      <td>Cyst</td>\n",
       "      <td>0</td>\n",
       "      <td>Cyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12442</th>\n",
       "      <td>12442</td>\n",
       "      <td>Cyst- (2627)</td>\n",
       "      <td>/content/data/CT KIDNEY DATASET Normal, CYST, ...</td>\n",
       "      <td>Cyst</td>\n",
       "      <td>0</td>\n",
       "      <td>Cyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>12443</td>\n",
       "      <td>Cyst- (972)</td>\n",
       "      <td>/content/data/CT KIDNEY DATASET Normal, CYST, ...</td>\n",
       "      <td>Cyst</td>\n",
       "      <td>0</td>\n",
       "      <td>Cyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12444</th>\n",
       "      <td>12444</td>\n",
       "      <td>Cyst- (2323)</td>\n",
       "      <td>/content/data/CT KIDNEY DATASET Normal, CYST, ...</td>\n",
       "      <td>Cyst</td>\n",
       "      <td>0</td>\n",
       "      <td>Cyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445</th>\n",
       "      <td>12445</td>\n",
       "      <td>Cyst- (2145)</td>\n",
       "      <td>/content/data/CT KIDNEY DATASET Normal, CYST, ...</td>\n",
       "      <td>Cyst</td>\n",
       "      <td>0</td>\n",
       "      <td>Cyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12446 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       image_id  \\\n",
       "0               0  Tumor- (1044)   \n",
       "1               1    Tumor- (83)   \n",
       "2               2   Tumor- (580)   \n",
       "3               3  Tumor- (1701)   \n",
       "4               4  Tumor- (1220)   \n",
       "...           ...            ...   \n",
       "12441       12441   Cyst- (2522)   \n",
       "12442       12442   Cyst- (2627)   \n",
       "12443       12443    Cyst- (972)   \n",
       "12444       12444   Cyst- (2323)   \n",
       "12445       12445   Cyst- (2145)   \n",
       "\n",
       "                                                    path   diag  target  Class  \n",
       "0      /content/data/CT KIDNEY DATASET Normal, CYST, ...  Tumor       3  Tumor  \n",
       "1      /content/data/CT KIDNEY DATASET Normal, CYST, ...  Tumor       3  Tumor  \n",
       "2      /content/data/CT KIDNEY DATASET Normal, CYST, ...  Tumor       3  Tumor  \n",
       "3      /content/data/CT KIDNEY DATASET Normal, CYST, ...  Tumor       3  Tumor  \n",
       "4      /content/data/CT KIDNEY DATASET Normal, CYST, ...  Tumor       3  Tumor  \n",
       "...                                                  ...    ...     ...    ...  \n",
       "12441  /content/data/CT KIDNEY DATASET Normal, CYST, ...   Cyst       0   Cyst  \n",
       "12442  /content/data/CT KIDNEY DATASET Normal, CYST, ...   Cyst       0   Cyst  \n",
       "12443  /content/data/CT KIDNEY DATASET Normal, CYST, ...   Cyst       0   Cyst  \n",
       "12444  /content/data/CT KIDNEY DATASET Normal, CYST, ...   Cyst       0   Cyst  \n",
       "12445  /content/data/CT KIDNEY DATASET Normal, CYST, ...   Cyst       0   Cyst  \n",
       "\n",
       "[12446 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsize = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "C0h3ndqZEsXT"
   },
   "outputs": [],
   "source": [
    "## Read in all images\n",
    "# First, read in all cyst images\n",
    "\n",
    "cystImages = []\n",
    "\n",
    "# Get the correct folder of images\n",
    "folder_dir = \"KidneyImages/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/Cyst\"\n",
    "\n",
    "\n",
    "for images in os.listdir(folder_dir): # For each item in the folder\n",
    "    if (images.endswith(\".jpg\")): # If it is a jpg\n",
    "        image = Image.open(folder_dir + '/' + images) # Open the image\n",
    "        image = image.resize(newsize) # Resize it to 256x256\n",
    "        npImage = np.asarray(image) # Turn it into an array\n",
    "        reshapedImage = npImage[:, :, 0] # Get rid of the last two color values (since it is black and white)\n",
    "        cystImages.append({'image_id': images[:-4], 'image': reshapedImage}) # Add the information to the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Nz5nTPfA8XzJ"
   },
   "outputs": [],
   "source": [
    "# Then all normal images\n",
    "normalImages = []\n",
    "\n",
    "folder_dir = \"KidneyImages/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/Normal\"\n",
    "\n",
    "\n",
    "for images in os.listdir(folder_dir):\n",
    "    if (images.endswith(\".jpg\")):\n",
    "        image = Image.open(folder_dir + '/' + images)\n",
    "        image = image.resize(newsize)\n",
    "        npImage = np.asarray(image)\n",
    "        reshapedImage = npImage[:, :, 0]\n",
    "\n",
    "        normalImages.append({'image_id': images[:-4], 'image': reshapedImage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Nynum1gE84tY"
   },
   "outputs": [],
   "source": [
    "# Then all stone images\n",
    "stoneImages = []\n",
    "\n",
    "folder_dir = \"KidneyImages/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/Stone\"\n",
    "\n",
    "\n",
    "for images in os.listdir(folder_dir):\n",
    "    if (images.endswith(\".jpg\")):\n",
    "        image = Image.open(folder_dir + '/' + images)\n",
    "        image = image.resize(newsize)\n",
    "        npImage = np.asarray(image)\n",
    "        reshapedImage = npImage[:, :, 0]\n",
    "\n",
    "        stoneImages.append({'image_id': images[:-4], 'image': reshapedImage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "i_nlQuIx-J-e"
   },
   "outputs": [],
   "source": [
    "# Then all tumor images\n",
    "tumorImages = []\n",
    "\n",
    "folder_dir = \"KidneyImages/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/Tumor\"\n",
    "\n",
    "\n",
    "for images in os.listdir(folder_dir):\n",
    "    if (images.endswith(\".jpg\")):\n",
    "        image = Image.open(folder_dir + '/' + images)\n",
    "        image = image.resize(newsize)\n",
    "        npImage = np.asarray(image)\n",
    "        reshapedImage = npImage[:, :, 0]\n",
    "\n",
    "        tumorImages.append({'image_id': images[:-4], 'image': reshapedImage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TrW3hRCtizO3"
   },
   "outputs": [],
   "source": [
    "# Concatenate all list of images, and turn into a data frame\n",
    "\n",
    "allImages = cystImages + stoneImages + normalImages + tumorImages\n",
    "\n",
    "imgs = pd.DataFrame(allImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cyst- (630)</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cyst- (260)</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cyst- (1631)</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cyst- (1261)</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cyst- (1774)</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12441</th>\n",
       "      <td>Tumor- (209)</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12442</th>\n",
       "      <td>Tumor- (1390)</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>Tumor- (659)</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12444</th>\n",
       "      <td>Tumor- (1685)</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445</th>\n",
       "      <td>Tumor- (2103)</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12446 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id                                              image\n",
       "0        Cyst- (630)  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "1        Cyst- (260)  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "2       Cyst- (1631)  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "3       Cyst- (1261)  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "4       Cyst- (1774)  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "...              ...                                                ...\n",
       "12441   Tumor- (209)  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "12442  Tumor- (1390)  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "12443   Tumor- (659)  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "12444  Tumor- (1685)  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "12445  Tumor- (2103)  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "\n",
       "[12446 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary of labels\n",
    "labelDictionary = {0: 'Cyst', 1: 'Normal', 2: 'Stone', 3:'Tumor'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with the other dataframe to get each image matched with its label\n",
    "imgWithLabel = imgs.merge(df, how = 'inner', on = 'image_id')\n",
    "imgWithLabel = imgWithLabel[['image', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imgWithLabel['image'].to_numpy()\n",
    "y = imgWithLabel['target'].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale the data between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12446, 256, 256)\n",
      "(12446, 65536)\n"
     ]
    }
   ],
   "source": [
    "# Reshape/ unpack the array of images, then flatten it so it is prepared for smote\n",
    "X = np.array([x for x in X])\n",
    "print(X.shape)\n",
    "nsamples, nx, ny = X.shape\n",
    "X = X.reshape((nsamples,nx*ny))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SMOTE to balance classes\n",
    "\n",
    "# Original class distribution\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "uniqueLables = [labelDictionary[x] for x in unique]\n",
    "plt.pie(counts, labels = uniqueLables)\n",
    "plt.title('Original Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Perform SMOTE sampling\n",
    "oversample = SMOTE()\n",
    "Xsmote, ysmote = oversample.fit_resample(X, y)\n",
    "\n",
    "\n",
    "# Updated class distribution\n",
    "uniquesmote, countssmote = np.unique(ysmote, return_counts=True)\n",
    "uniqueLablessmote = [labelDictionary[x] for x in uniquesmote]\n",
    "plt.pie(countssmote, labels = uniqueLablessmote)\n",
    "plt.title('Post Smote Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle & reshape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "indices = np.arange(Xsmote.shape[0])\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "Xshuffled = Xsmote[shuffled_indices]\n",
    "yshuffled = ysmote[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to 4 dimensional data for augmentation\n",
    "Xshuffled = Xshuffled.reshape((20308,256,256,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = plt.imshow(Xshuffled[1,:,:,:],cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xshuffled, yshuffled, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an intermediary validation set \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmentation layers\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.RandomFlip(\"horizontal\"),\n",
    "        keras.layers.RandomRotation(0.1),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "example_image = X_train[2]\n",
    "print(example_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rotate_image(image):\n",
    "#     # Random angle between -20 and 20 degrees\n",
    "#     angle = np.random.uniform(-20, 20)\n",
    "#     rotated_image = np.interp(np.arange(len(image)), np.arange(len(image)) + angle, image, left=0, right=0)\n",
    "#     return rotated_image\n",
    "\n",
    "# def zoom_image(image):\n",
    "#     # Random zoom factor between 0.8 and 1.2\n",
    "#     zoom_factor = np.random.uniform(0.8, 1.2)\n",
    "#     zoomed_image = np.interp(np.arange(len(image)), np.arange(len(image)) * zoom_factor, image, left=0, right=0)\n",
    "#     return zoomed_image\n",
    "\n",
    "# def flip_image(image):\n",
    "#     # Randomly flip the image horizontally\n",
    "#     if np.random.rand() > 0.5:\n",
    "#         flipped_image = np.flip(image)\n",
    "#     else:\n",
    "#         flipped_image = image\n",
    "#     return flipped_image\n",
    "\n",
    "# def augment_image(image):\n",
    "#     # Apply rotation\n",
    "#     rotated_image = rotate_image(image)\n",
    "    \n",
    "#     # Apply zoom\n",
    "#     zoomed_image = zoom_image(rotated_image)\n",
    "    \n",
    "#     # Apply flip\n",
    "#     flipped_image = flip_image(zoomed_image)\n",
    "\n",
    "#     return flipped_image\n",
    "\n",
    "# # Perform image augmentation on the training data\n",
    "# X_train_augmented = [augment_image(image) for image in X_train]\n",
    "\n",
    "# # Convert the augmented data back to NumPy array\n",
    "# X_train_augmented = np.array(X_train_augmented)\n",
    "\n",
    "# # Concatenate the original and augmented data\n",
    "# X_train_combined = np.concatenate((X_train, X_train_augmented))\n",
    "# y_train_combined = np.concatenate((y_train, y_train.copy()))  \n",
    "\n",
    "# # Ensure X_train_combined and y_train_combined have the correct shapes\n",
    "# print(X_train_combined.shape)\n",
    "# print(y_train_combined.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train_combined \n",
    "# y_train = y_train_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.stack(X_train, axis=0)\n",
    "# Y_train = np.stack(y_train, axis=0)\n",
    "# X_test = np.stack(X_test, axis=0)\n",
    "# Y_test = np.stack(y_test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multiclass_model(n_classes, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Build a multi-class logistic regression model using Keras.\n",
    "\n",
    "    Args:\n",
    "    n_classes: Number of classes in the dataset\n",
    "    learning_rate: The desired learning rate for SGD.\n",
    "\n",
    "    Returns:\n",
    "    model: A tf.keras model (graph).\n",
    "    \"\"\"\n",
    "   \n",
    "    model = keras.Sequential([\n",
    "        data_augmentation,\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units=n_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "model = build_multiclass_model(4, 0.01)\n",
    "\n",
    "history = model.fit(\n",
    "  x = X_train,\n",
    "  y = y_train,\n",
    "  epochs=5,\n",
    "  batch_size=128,\n",
    "  validation_split=0.1,\n",
    "  verbose=1)\n",
    "\n",
    "history = pd.DataFrame(history.history)\n",
    "display(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = np.argmax(model.predict(X_val), axis=-1)\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix as a 2D array.\n",
    "confusion_matrix = tf.math.confusion_matrix(y_val, test_predictions)\n",
    "\n",
    "# Use a heatmap plot to display it.\n",
    "ax = sns.heatmap(confusion_matrix, annot=True, fmt='.3g', cmap='Blues',\n",
    "                 xticklabels=['Cyst','Normal','Stone','Tumor'], yticklabels=['Cyst','Normal','Stone','Tumor'], \n",
    "                 cbar=False)\n",
    "\n",
    "# Add axis labels.\n",
    "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_classes,   #should we change the n_classes to 4? since we only have 4 classes\n",
    "                hidden_layer_sizes=[],\n",
    "                activation='relu',\n",
    "                optimizer='SGD',\n",
    "                learning_rate=0.01):\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # Flatten the input shape\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    # Add hidden layers\n",
    "    for layer_size in hidden_layer_sizes:\n",
    "        model.add(tf.keras.layers.Dense(layer_size, activation=activation))\n",
    "    #Add the last neural network layer\n",
    "    model.add(tf.keras.layers.Dense(units=n_classes, activation='softmax'))\n",
    "    if optimizer == 'SGD':\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    elif optimizer == 'Adam':\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    elif optimizer == 'RMSprop':\n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid optimizer. Please choose from ‘SGD’, ‘Adam’, or ‘RMSprop’.\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the shape\n",
    "#### I don't think we need these anymore since I reshaped before smote!\n",
    "# X_train = np.array([np.asarray(x).flatten() for x in X_train]).astype(np.float32)\n",
    "# y_train = np.array([np.asarray(y) for y in y_train]).astype(np.float32)\n",
    "# X_test = np.array([np.asarray(x).flatten() for x in X_train]).astype(np.float32)\n",
    "# y_test = np.array([np.asarray(y) for y in y_train]).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Build and compile the model\n",
    "model = build_model(n_classes=4, hidden_layer_sizes=[128], activation='relu', optimizer='SGD', learning_rate=0.01)\n",
    "\n",
    "# Train the model for 5 epochs\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1, verbose=1)\n",
    "test_loss, test_accuracy = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "plt.plot(train_accuracy, label='train_accuracy')\n",
    "plt.plot(val_accuracy, label='validation accuracy')\n",
    "plt.xticks(range(5))\n",
    "plt.xlabel('Train epochs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(n_classes=4, hidden_layer_sizes=[128], activation='relu', optimizer='RMSprop', learning_rate=0.01)\n",
    "\n",
    "# Train the model for 5 epochs\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1, verbose=1)\n",
    "test_loss, test_accuracy = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "plt.plot(train_accuracy, label='train_accuracy')\n",
    "plt.plot(val_accuracy, label='validation accuracy')\n",
    "plt.xticks(range(5))\n",
    "plt.xlabel('Train epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(n_classes=4, hidden_layer_sizes=[128], activation='relu', optimizer='Adam', learning_rate=0.01)\n",
    "\n",
    "# Train the model for 5 epochs\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1, verbose=1)\n",
    "test_loss, test_accuracy = model.evaluate(X_val, y_val, verbose=2)\n",
    "\n",
    "\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "plt.plot(train_accuracy, label='train_accuracy')\n",
    "plt.plot(val_accuracy, label='validation accuracy')\n",
    "plt.xticks(range(5))\n",
    "plt.xlabel('Train epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_cnn_model(input_shape, n_classes, optimizer='SGD', learning_rate=0.01):\n",
    " \n",
    "    np.random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Dense layers\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    if optimizer == 'SGD':\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    elif optimizer == 'Adam':\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    elif optimizer == 'RMSprop':\n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid optimizer. Please choose from ‘SGD’, ‘Adam’, or ‘RMSprop’.\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)  # Change this according to your image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shape = (32, 32, 3)  \n",
    "X_train_reshaped = np.reshape(X_train, (-1, 256, 256, 1))  \n",
    "X_val_reshaped = np.reshape(X_val, (-1, 256, 256, 1))  \n",
    "X_test_reshaped = np.reshape(X_test, (-1, 256, 256, 1)) \n",
    "# Normalize pixel values to range [0, 1]\n",
    "X_train_reshaped = X_train_reshaped / 255.0\n",
    "X_val_reshaped = X_val_reshaped / 255.0\n",
    "X_test_reshaped = X_test_reshaped / 255.0\n",
    "\n",
    "\n",
    "X_train_resized = np.array([tf.image.resize(image, (32, 32)) for image in X_train_reshaped])\n",
    "X_val_resized = np.array([tf.image.resize(image, (32, 32)) for image in X_val_reshaped])\n",
    "X_test_resized = np.array([tf.image.resize(image, (32, 32)) for image in X_test_reshaped])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rgb = np.repeat(X_train_resized[..., np.newaxis], 3, axis=-1)\n",
    "X_val_rgb = np.repeat(X_val_resized[..., np.newaxis], 3, axis=-1)\n",
    "X_test_rgb = np.repeat(X_test_resized[..., np.newaxis], 3, axis=-1)\n",
    "\n",
    "# Reshape to remove the extra dimension\n",
    "X_train_rgb = np.squeeze(X_train_rgb, axis=3)\n",
    "X_val_rgb = np.squeeze(X_val_rgb, axis=3)\n",
    "X_test_rgb = np.squeeze(X_test_rgb, axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CNN model for 5 epochs\n",
    "cnn_model = build_cnn_model(input_shape, n_classes=4, optimizer='SGD', learning_rate=0.01)\n",
    "history_cnn = cnn_model.fit(X_train_rgb, y_train, epochs=10, batch_size=64, validation_split=0.1, verbose=1)\n",
    "test_loss_cnn, test_accuracy_cnn = cnn_model.evaluate(X_val_rgb, y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_cnn = history_cnn.history['accuracy']\n",
    "val_accuracy_cnn = history_cnn.history['val_accuracy']\n",
    "\n",
    "plt.plot(train_accuracy_cnn, label='train_accuracy_cnn')\n",
    "plt.plot(val_accuracy_cnn, label='validation accuracy_cnn')\n",
    "plt.xticks(range(5))\n",
    "plt.xlabel('Train epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = build_cnn_model(input_shape, n_classes=4, optimizer='Adam', learning_rate=0.01)\n",
    "history_cnn = cnn_model.fit(X_train_rgb, y_train, epochs=10, batch_size=64, validation_split=0.1, verbose=1)\n",
    "test_loss_cnn, test_accuracy_cnn = cnn_model.evaluate(X_val_rgb, y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_cnn = history_cnn.history['accuracy']\n",
    "val_accuracy_cnn = history_cnn.history['val_accuracy']\n",
    "\n",
    "plt.plot(train_accuracy_cnn, label='train_accuracy_cnn')\n",
    "plt.plot(val_accuracy_cnn, label='validation accuracy_cnn')\n",
    "plt.xticks(range(5))\n",
    "plt.xlabel('Train epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = build_cnn_model(input_shape, n_classes=4, optimizer='RMSprop', learning_rate=0.01)\n",
    "history_cnn = cnn_model.fit(X_train_rgb, y_train, epochs=10, batch_size=64, validation_split=0.1, verbose=1)\n",
    "test_loss_cnn, test_accuracy_cnn = cnn_model.evaluate(X_val_rgb, y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_cnn = history_cnn.history['accuracy']\n",
    "val_accuracy_cnn = history_cnn.history['val_accuracy']\n",
    "\n",
    "plt.plot(train_accuracy_cnn, label='train_accuracy_cnn')\n",
    "plt.plot(val_accuracy_cnn, label='validation accuracy_cnn')\n",
    "plt.xticks(range(5))\n",
    "plt.xlabel('Train epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test CNN Model and Create ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn_model.predict(X_test_rgb)\n",
    "class_predictions = np.argmax(predictions, axis=-1)\n",
    "print(class_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "num_classes = np.max(y_test) + 1  # Assuming class indices start from 0\n",
    "y_test_onehot = label_binarize(y_test, classes=np.arange(num_classes))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(4):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_onehot[:,i], predictions[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot the ROC curve for each class\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(4):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label='ROC curve (area = {:.2f}) for class {}'.format(roc_auc[i], i))\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Multi-Class CNN')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12184, 256, 256, 1) (4062, 256, 256, 1)\n",
      "(12184, 256, 256, 3) (4062, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Should have shape (12184, 256, 256, 1) at start of cell\n",
    "\n",
    "print(X_train.shape, X_val.shape)\n",
    "X_train_3_channel = X_train.repeat(3, axis=-1)\n",
    "X_val_3_channel = X_val.repeat(3, axis = -1)\n",
    "\n",
    "print(X_train_3_channel.shape, X_val_3_channel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base model\n",
    "base_model = keras.applications.Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(256, 256, 3),\n",
    "    include_top=False)\n",
    "# Freeze base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [       keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "               keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(256, 256, 3))\n",
    "x = data_augmentation(inputs) \n",
    "x = tf.keras.applications.xception.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "outputs = keras.layers.Dense(4)(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "191/191 [==============================] - 775s 4s/step - loss: 1.4151 - accuracy: 0.2545 - val_loss: 1.3863 - val_accuracy: 0.2905\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 757s 4s/step - loss: 1.3863 - accuracy: 0.2587 - val_loss: 1.3863 - val_accuracy: 0.2905\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 752s 4s/step - loss: 1.3863 - accuracy: 0.2494 - val_loss: 1.3863 - val_accuracy: 0.2905\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 751s 4s/step - loss: 1.3863 - accuracy: 0.2540 - val_loss: 1.3863 - val_accuracy: 0.2905\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 756s 4s/step - loss: 1.3863 - accuracy: 0.2554 - val_loss: 1.3863 - val_accuracy: 0.2905\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 752s 4s/step - loss: 1.3863 - accuracy: 0.2562 - val_loss: 1.3863 - val_accuracy: 0.2905\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 753s 4s/step - loss: 1.3863 - accuracy: 0.2498 - val_loss: 1.3863 - val_accuracy: 0.2905\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 752s 4s/step - loss: 1.3863 - accuracy: 0.2523 - val_loss: 1.3863 - val_accuracy: 0.2905\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 752s 4s/step - loss: 1.3863 - accuracy: 0.2588 - val_loss: 1.3863 - val_accuracy: 0.2905\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 752s 4s/step - loss: 1.3863 - accuracy: 0.2489 - val_loss: 1.3863 - val_accuracy: 0.2905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb20f6b8b80>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train_3_channel, y_train, epochs=10, batch_size=64, validation_data = (X_val_3_channel, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
